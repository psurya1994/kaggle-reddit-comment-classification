{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good reference for stacking: https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading needed libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for multinoulli NB\n",
    "df = pd.read_csv('reddit_train.csv')\n",
    "df2 = pd.read_csv('reddit_test.csv')\n",
    "# df = df.sample(5000, random_state=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_id'], mapping = df['subreddits'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "features = tfidf.fit_transform(df.comments)\n",
    "features_test = tfidf.transform(df2.comments)\n",
    "\n",
    "labels = df.category_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for fine tuning and check which models are the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.3803\n",
      "0.1 0.4564\n",
      "1 0.53595\n",
      "10 0.53895\n"
     ]
    }
   ],
   "source": [
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    gNB = LogisticRegression(C=C)\n",
    "    gNB.fit(features[:50000,:],labels[:50000])\n",
    "    print(C, np.mean(gNB.predict(features[50000:,:])==labels[50000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from a sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(classifier):\n",
    "    classifier.fit(features, labels)\n",
    "    f1 = classifier.predict_proba(features)\n",
    "    f2 = classifier.predict_proba(features_test)\n",
    "    print(' training accuracy: ', np.mean(classifier.predict(features)==labels))\n",
    "    return f1, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training accuracy:  0.8171285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training accuracy:  0.7188571428571429\n"
     ]
    }
   ],
   "source": [
    "m1_train, m1_test = getFeatures(MultinomialNB(0.2))\n",
    "m2_train, m2_test = getFeatures(LogisticRegression(C=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from pytorch models (saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions\n",
    "def pickle2np(filename=\"preds/bert-preds-test.p\"):\n",
    "    tmp = pickle.load( open( filename, \"rb\" ) )\n",
    "    preds = list()\n",
    "    for i in range(len(tmp)):\n",
    "        for j in range(len(tmp[i])):\n",
    "            preds.append(list(tmp[i][j]))\n",
    "            \n",
    "    return np.array(preds)\n",
    "\n",
    "m3_train = pickle2np(\"preds/bert-preds-train.p\")\n",
    "m3_test = pickle2np(\"preds/bert-preds-test.p\")\n",
    "m4_train = pickle2np(\"preds/xlnet-preds-train.p\")\n",
    "m4_test = pickle2np(\"preds/xlnet-preds-test.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking the features\n",
    "features = np.concatenate((m1_train, m2_train, m3_train, m4_train),axis=1)\n",
    "test_features = np.concatenate((m1_test, m2_test, m3_test, m4_test),axis=1)\n",
    "labels = df.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you want to work on a smaller sample\n",
    "samples = np.random.randint(70000,size=(1000))\n",
    "features = features[samples,:]\n",
    "labels = df.category_id[samples]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/network/home/penmetss/fastai/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  2.7757182121276855\n",
      "XGBClassifier\n",
      "time taken:  23.492751121520996\n",
      "AdaBoostClassifier\n",
      "time taken:  2.286252021789551\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [\n",
    "#     RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "#     LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "#     GaussianNB(),\n",
    "#     KNeighborsClassifier(),\n",
    "#     GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print(model_name)\n",
    "    start_time = time()\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    print('time taken: ', time()-start_time)\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.499380</td>\n",
       "      <td>0.123815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.741195</td>\n",
       "      <td>0.040745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.804769</td>\n",
       "      <td>0.058318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean Accuracy  Standard deviation\n",
       "model_name                                           \n",
       "AdaBoostClassifier       0.499380            0.123815\n",
       "LinearSVC                0.741195            0.040745\n",
       "XGBClassifier            0.804769            0.058318"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tuning the meta learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.89\n",
      "0.1 0.9\n",
      "0.2 0.88\n",
      "0.3 0.88\n",
      "1 0.85\n"
     ]
    }
   ],
   "source": [
    "for eta in [0.01, 0.1, 0.2, 0.3, 1]:\n",
    "    gNB = XGBClassifier(learning_rate=eta)\n",
    "    gNB.fit(features[:900,:],labels[:900])\n",
    "    print(eta, np.mean(gNB.predict(features[900:,:])==labels[900:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit classifier on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709.6374371051788\n"
     ]
    }
   ],
   "source": [
    "reg = XGBClassifier()\n",
    "start_time = time()\n",
    "reg.fit(features,labels)\n",
    "print(time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8832428571428571\n"
     ]
    }
   ],
   "source": [
    "# get predictions and training accuracy\n",
    "print(np.mean(reg.predict(features)==labels))\n",
    "preds = reg.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame()\n",
    "test_preds['Id'] = df2['id']\n",
    "test_preds['Category'] = mapping[preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='test.csv' target='_blank'>test.csv</a><br>"
      ],
      "text/plain": [
       "/network/home/penmetss/comp551/test.csv"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.to_csv(\"test.csv\", index=False)\n",
    "from IPython.display import FileLink, FileLinks\n",
    "FileLink('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
