{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only contains one csv file, let's have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>responsible for the change to the draft lottery . xxbos xxmaj ah yes way could have been :( remember when he was drafted i thought he was gon na be great but nope could have had kawhi xxmaj thompson or jimmy butler xxbos https : / / youtu.be / xxunk \\n \\n  xxmaj if you did n't find it already . \\n \\n  xxmaj nothing out of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>better xxup qb then xxmaj wentz in the next two years xxbos xxmaj adults who smoke weed . \\n \\n  i get the attraction , annnd i 'm not going to say anything against you , i 'm not gon na be an ass about it or anything . i just find it distasteful for no real reason . i think it might be because i know shitty potheads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>contributed to this rise . xxmaj he specifically said in 2008 before he was elected , that high gas prices are n't a problem , that xxmaj americans are mad only because they rose so high so quickly . xxmaj he would prefer a gradual price increase . xxmaj the administration has refused to permit increased energy production domestically . \\n \\n  xxmaj the administration is doing this even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i immediatly recognized him . xxbos xxmaj it takes on a pretty realistic and tame approach to middle school romance ( the awkwardness , the inexperience , etc ) which is n't necessarily all that interesting at times . xxmaj this is most notable when looking at the characters themselves . xxmaj depending on how much you enjoy watching average , shy 13 - 14 yo 's interact your mileage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>successful enough to warrant a sequel . \\n  xxbos [ xxunk - xxmaj road of xxmaj xxunk : / / www.youtube.com / watch?v = xxunk ) , xxmaj herman xxmaj li and xxmaj sam xxmaj xxunk from dragonforce are involved on the guitar arrangements . xxbos xxup xxunk , xxunk , xxmaj talking xxmaj heads . xxmaj this and xxmaj california punk were constantly playing in my bedroom when</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_train.csv')\n",
    "df2 = pd.read_csv('reddit_test.csv')\n",
    "df = df.drop(['subreddits', 'id'],axis=1)\n",
    "df2 = df2.drop(['id'],axis=1)\n",
    "df = df.append(df2)\n",
    "bs=64\n",
    "data_lm = (TextList.from_df(df).split_by_rand_pct(0.1).label_for_lm().databunch(bs=bs))\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_train.csv')\n",
    "# df = df.iloc[np.random.permutation(len(df))]\n",
    "train_df = df[:45000]\n",
    "val_df = df[60000:]\n",
    "# df['label'] = df['subreddits']\n",
    "# df['text'] = df['comments']\n",
    "# df = df.drop(['comments', 'subreddits', 'id'],axis=1)\n",
    "# df = df.dropna()\n",
    "# df.to_csv(\"reddit_train_fast.csv\", index=None)\n",
    "# print(df.head())\n",
    "\n",
    "# df = pd.read_csv('reddit_train_fast.csv', header='infer')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Honestly, Buffalo is the correct answer. I rem...</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ah yes way could have been :( remember when he...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He wouldn't have been a bad signing if we woul...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Easy. You use the piss and dry technique. Let ...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           comments       subreddits\n",
       "0   0  Honestly, Buffalo is the correct answer. I rem...           hockey\n",
       "1   1  Ah yes way could have been :( remember when he...              nba\n",
       "2   2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...  leagueoflegends\n",
       "3   3  He wouldn't have been a bad signing if we woul...           soccer\n",
       "4   4  Easy. You use the piss and dry technique. Let ...            funny"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataBunch.from_df('',train_df=train_df, valid_df=val_df, text_cols='comments',label_cols='subreddits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
    "\n",
    "Before we delve into the explanations, let's take the time to save the things that were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj no hype to save these shows now . xxmaj these shows are ranked according to how i thought they did in pure comparison to each other . xxmaj only scoring finished shows , so i only have ten instead of my usual thirteen . xxup mal scores are still xxunk . \\n \\n  xxmaj rank | xxmaj anime | xxmaj score \\n  : xxunk \\n</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * xxmaj glassjaw * * \\n  [ artist pic](https : / / lastfm-img2.akamaized.net / i / u / 252 / xxunk ) \\n \\n  &gt; xxmaj glassjaw is a highly influential post - hardcore band from xxmaj long xxmaj island , xxup ny . xxmaj they formed in the summer of 1993 after xxmaj palumbo and xxmaj beck met each other at camp . xxmaj they</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this was like 6 - 7 years ago , i was working in a 1 $ store . xxmaj we 'd be assigned position for cashier and the 1st cashier would call us for back up in order when needed ( so 2nd cashier was going to be there pretty much all day , and 4th cashier and below were going to spend most of their day restocking</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * xxmaj britain faces up to xxmaj brexit * * \\n \\n  xxmaj as long as the government stays in denial about xxmaj brexit â€™s drawbacks , the country is on course for disaster \\n \\n  xxmaj jul 22nd 2017 \\n \\n  xxup crisis ? xxmaj what crisis ? xxmaj so many have been triggered in xxmaj britain by the vote a year ago to</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos &gt; \" xxmaj but you ca n't accept this argument because you have no counterargument ... \" \\n \\n  &gt; \" ... you 'll carry on ignoring me . \" \\n \\n  &gt; \" xxmaj you have no fucking clue , do you ... ? \\n  xxmaj everything i say is just ignored because it ca nt get past your giant xxunk ego . xxmaj it</td>\n",
       "      <td>Overwatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab the full dataset for what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/network/home/penmetss/.fastai/data/imdb/test'),\n",
       " PosixPath('/network/home/penmetss/.fastai/data/imdb/README'),\n",
       " PosixPath('/network/home/penmetss/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/network/home/penmetss/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
    "\n",
    "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipedia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word is, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust the parameters of our model by a little bit. Plus there might be some words that would be extremely common in the reviews dataset but would be barely present in wikipedia, and therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
    "\n",
    "The line before being a bit long, we want to load quickly the final ids by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just has eye constant eye contact . xxbos xxmaj he would n't have been a bad signing if we would n't have paid 18 m euros . xxmaj for the right price he would have been acceptable . xxbos xxmaj easy . xxmaj you use the piss and dry technique . xxmaj let a few drops out , let it dry , rinse and repeat . xxmaj if you get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>touch , shadow word pain , swap target . xxbos xxmaj you got it wrong , since you can only view ( and get credit for ) an objective once you 've done the one before it . = p \\n \\n  xxrep 12 ^ . \\n  xxup ^^^i xxunk xxunk xxunk xxunk xxunk xxunk ... \\n  xxbos xxmaj alex xxmaj xxunk . a common claim from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>blood test , and you ca n't refuse that . \\n \\n  xxmaj and you do n't want the blood test because they will extrapolate the time since you last drove and add that to your blood xxunk level . \\n \\n  xxmaj the only chance you have is to comply . xxmaj you ca n't outsmart the system . xxbos my guess would be after or during</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxup rb . xxup gb does nt need to be conservative . xxmaj my way of thinking was the xxmaj rams xxunk give up their best offensive weapon for a 2nd . xxmaj you re getting an elite xxup rb so xxmaj rodgers does nt have to do everything , every week . xxbos is that you talking xxmaj mr. xxmaj xxunk ? xxmaj or is it the liquor ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>posted on here . \\n \\n  xxmaj the guy is not our friend in any sense of the word . xxbos xxmaj new superstar xxmaj xxunk xxmaj sr . takes xxmaj argentinian football by storm - 2018 headline . xxbos i liked xxmaj hugo , but i felt his performance in xxmaj cap 1 was just a little over the top . xxmaj which is actually xxunk fine for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU5dn/8c+VTPaVkIQlCYR9hwBhU1CoFteqWKyiVqxa9HF72trleerzs4vVbnbRumu12rpWi7uAGyK7CYuEPUAChCUrSciezP37YwaJMSETMidnluv9es2LyZlz5lw3k+Sbc8597luMMSillFLeFmJ3AUoppQKTBoxSSilLaMAopZSyhAaMUkopS2jAKKWUsoTD7gK8KTk52WRmZtpdhlJK+Y3c3NxSY0yKFe8dUAGTmZlJTk6O3WUopZTfEJFCq95bT5EppZSyhAaMUkopS2jAKKWUsoQGjFJKKUtowCillLKEBoxSSilLaMAopZSyhAaMj1qSd5g9Jcct3UdlXRM6XYNSyioBdaPl6Xp5/X6mDe7NoOQYu0sBXL/4b3txIwN7R/PenbOIDAv16vs3tzi5/70dPLNqHylxEcwcmsyZQ5OZOTSZvgmRXt2XUip4BX3AVNY1cd9726lrbOGaaQO445xhJMdG2FrTyt2ltDgNe0tqePCj3fzs/JFee++KmkZuf2kDq/LLmD85ncZmJyt2lbB4YxEAZwzpzcIzMjlnZCqOUD3AVUqdvqAPmISoMD6662we/HA3/1q3n9dyD3Lz2UO4adYgosPt+e9ZvrOY+EgHc8f05ckVe7lgbF/Gpyd2+313Ha3mpudyOFJZzx/nj+eK7AwAnE7DzqPVfLT9KC+u28/N/8wlLTGKa6cP5MopGSTFhHd730qp4COBdA4+OzvbdGcssj0lx/nDkh0s3XqUQckxPHz1RMb0T/BihZ0zxjD1/o+YOiiJ++eNY+5fPqVXdDhv3T6TcEfHRxRbD1Xyj1UFlNU0uh7HG6hpaCbcEUJkWCgRjhAOlNcRG+ngie9OZtKAXu2+T3OLkw+3F/Pc6gLW7C0j3BHCxeP7cd2MTLIyTh1yxVX1FJbXEhvhIDbCQXxkGLGRDkJDpFv/J0op64hIrjEm25L31oD5utV7SvnhK5uoqG3inotHc820AYh0/EvyWG0juYUVjEtPIDWue9cw8ooqufhvK3ngignMn5zOh9uOctPzOfzw3OH897nD2t2mxWmY+5dPOVJZT2ZyDL1jI+gdE05shIPGZicNzS3UNzmJiXDwk/NGeHydZdfRav65ppD/bDhITWML49MTuCwrjW+MTCWz1fWqbYeqePqzvby1+RDNzq9+P4m4jhKTosNJiglnSEosPz1/BL1tPg2plHLRgPGQtwIGoOx4Az96dTOf7irhovH9+N3l44iLDPvaes0tThY8tZbPCyoAGNg7mskDezFrWDKXZaWdMpja88gn+fxx6U4+v/tcUuJcv4TvfGkj7+cd5u07ZjKyb/zXtnn3i8Pc9uIGHrl6EheN73carT214w3NLN5wkH+t3c/Oo9UADEqO4ezhKeQXH2dlfinR4aFcOSWD2SNSqW1oprqhmer6ZirrmqioaaS8tpGKmkZyCivoFR3GQ1dNZNrg3l6vVSnVNRowHvJmwIDr2sQTK/bywLKdDE2J5aVF0792PeIPS3bw6PI9/Oz8kYSGQE5BBbmFFZTVNLJwxkB+ecmYLoXMFY+vpq6phXfumPXlsvKaRr7550/pnxjFf249g7BWF9+NMVzw4Gc0tThZ9sOzLT8dVVhWw/KdJXy8o5g1e8voFR3G9WcM4uqpA0iI/noAt7X1UCW3v7iRwrIa7po7gv86ewghegpNKdtowHjI2wFzwsrdpdz43OcMSYnlxe9PIzHaFTKf7iph4TPruTI7g9/PH//l+sYY7n9vO099tq9LIVNZ28TEe5dx6+yh/Pi8EV957cRRyo/nDuf2b5w8VfbBtqN8//kc/vydCVw+Kd1LLfZMQ3MLjpCQLodadX0TP1+cx9ubD3HW8BQevnoi8e0cHSqlrGdlwGg/VA/MHJbMk9dlk198nOueWU9VfRNHq+r50SubGNEnjl9eMuYr64sIP79wFDfNHMRzawr51dvbPLqh8bP8EpwG5oz8+uRyF43vx8Xj+/HgR7vZfrgKcAXZwx/vJiMpiksm9PdOY7sgwhF6WkdMcZFhPHRVFvfNG8uaPaVc+cRaiqvrLahQKWUnDRgPnT08hUevmcS2Q1Vc/8x67nhpI7WNLTxyzUSiwr9+I6SIcPdFo7hx5iD+sbqAX761lcq6plPuY/nOEhKiwsjKaL+H168vHUtCVBh3vbqZphYnn+0uZfPBSm6dPdTv7lkREa6ZNpC/L5xCYVkN8x9bQ2FZjd1lKaW8yL9+K9ns3NF9ePjqiWw+WMn6feX85rKxDE2N63B9EeH/3CHz3JpCsn69jIse+ox739nGh9uO0tKqx5XTafh0VwmzhiV3eFSQFBPO/fPGse1wFQ9/nM/fPt5Nv4RILp+U5vW29pSzhqfwwk3TqK5v4tuPrWHroUq7S1JKeYml12BEpACoBlqA5o7O84nIFGANcJUx5jX3shZgi3uV/caYSzrbn1XXYNr6ZEcxBWU1fO/MQR6tb4whp7CCVfmlrNtbTu7+ChqbnUwfnMRDCyaSGhf5te7Jp/LDVzbx5qYinAZ+dckYFp6R6YVW2Su/uJrv/n09x+ubef7GqUzs4D4dpZR3+e1FfnfAZBtjSk+xTijwAVAPPNMqYI4bY2K7sr+eCpjuamhu4c2Nh7jnrTz39YiJ5BaW88CyXV/pntyRY7WNzP3LCpwGVv5sjtfHKrPLoWN1LHhqLRU1jby0aHqP3+SqVDAK9ID5AdAETAHeCYaAOWHHkSpufWEDBaU19IoOp39iFG/fMdOjbQ9W1NLY7GRwSpf+i3zewYpavvP4Ghqanbxy8/RTnoJUSnWfP/ciM8AyEckVkUVtXxSRNGAe8Fg720aKSI6IrBWRyzragYgscq+XU1JS4r3Ke8DIvvG8dftMLhzXj7KaRuaMTPV42/Re0QEXLuBq1wvfn+7qBPD0OvaX1dpdklLqNFl9BJNmjCkSkVRcp8HuMMasaPX6v4E/GWPWisg/+OoRzIltBwMfA+cYY/acan/+dgRzgjGGdfvKycpIDJjTXd2180g1Vz25hpgIB6/ePIP+iVF2l6RUQPLbIxhjTJH732JgMTC1zSrZwMvuU2nzgUdPHK202nYvsByYaGWtdhIRpg/ureHSyoi+cTx/wzQqa5u49ul1ep+MUn7IsoARkRgRiTvxHJgL5LVexxgzyBiTaYzJBF4DbjXGvCEivUQkwr1tMnAmsM2qWpVvGpeewD9umMKRqnqufXod5TWNdpeklOoCK49g+gArRWQzsB541xizRERuEZFbOtl2FJDj3vYT4HfGGA2YIDR5YBJPX5dNYVkt3/37uk5vVlVK+Q4di0z5hU92FrPo+RzGpiXw/VmDKa9p5FhtIxW1TYQ7QugdE07v2HCSYiLIykgkIcp7Y5tV1jURH+no8sjYSvkDv+2m3NM0YALbkrwj3Pbihq+MgBAdHkpjs/Mr89CkJUbx6i0zSPNCx4A3NxXxg1c20T8hitkjUpg9IpUzhvQmJiLoJ4NVAUIDxkMaMIHvYEUt1fXNJMWEkxgdRoQjFGMMVfXNlNc0sqf4OD98dRNJMeG8evMM+sR3PrlaY7Oz3dlCcwsrWPDUWkb1iyc1LoJV+aXUNrYQHhrC988axJ3nDCPC0fWOGSXVDewrrSEqLJSocNeMo8mxEdrJQ9lCA8ZDGjAKYOP+Cq59eh19EyJ5edGMDkdGMMbwm3e388K6Qn5+4Si+O33gl6fBDlbUctkjq4iJcPDGrWfSKyacxmYnOQXl/Dv3IIs3FjGybxwPXDGBsWmejTiwcX8Fz60u4N0th2lq+erPXWJ0GH+9MovZIzy/F0opb9CA8ZAGjDph/b5yFj6zngFJ0e1OFAfwxKd7+O37OxiQFM3+8lrOHp7CH+ePJzrCwfzHVlN0rI7Ft57J0NSv39D68Y6j/M/rWyivaeTWOUO5bsZAeseEf+U6TWOzk51Hqtl4oILXNxSx+cAxYiMcXJGdzuwRqTQ1O6lraqGusYVnVxew40gVPzp3OLfNGaqTsKkeowHjIQ0Y1drq/FK+94/PSUuM4r5545gx5OQUzW9uKuK/X97kmmPnqom8sK6Q+9/bTlRYKENSYtl44Bj/+N4UZg37+tw8J1TWNvHLt7eyeGMRADHhoWQkRZORFE1JdQPbDlfR2OwEYHBKDAtnZPLtyenEtnP9pq6xhf/9zxe8sekQ547qw5+vnKCTsKkeoQHjIQ0Y1dbavWX85LXNHCiv4/KJafz8olHsPFLN9c+uZ/LAXjx3w9Qvr6PkFx/nh69sYktRJb++dAzXzcj0aB85BeVsKapkf3ktB8pr2V9eS2JUOFkDEpmQnsiEjATSEqM67YVmjOG51QX85t3txEU66BV98qgrOiKU62Zk8u1J6ZZPi62CiwaMhzRgVHvqm1p4+ON8nlixh6iwUJzmZE+ztt2Zm1qc5BcfZ1S/eJuqhc8Lynlx3f6v9IzbU3ycbYerGJYay0/OG8E3R/fRbtPKKzRgPKQBo04lv7iae97cysGKOl5eNN2vxjczxvB+3hEeWLqTvaU1TBqQyI/PG8EZQ5LtLk35OQ0YD2nAKE8YY/z2r//mFiev5R7krx/u5khVPWcO7c1dc0cwSSdoU6dJA8ZDGjAqWNQ3tfDCuv08+kk+ZTWNnDMylfvmjaNvQuf3/SjVmt+OpqyUskZkWCg3zhzEip/O4afnj2DN3jJue3EDzS1Ou0tT6ksaMEr5sZgIB7fOHsrvvj2e3MIK/vrhbrtLUupLGjBKBYBLJvTnO9npPLI8n9X5Hc5QrlSP0oBRKkD88pIxDE6O4QevbKLseIPd5SilAaNUoIgOd/C3BZM4VtfEj/+9GaczcDrwKP+kAaNUABndP567LxzFJztL+H9v5lHX2GJ3SSqI6aQWSgWY62YM5GBFLU99to/Ve8p44IrxTB6YZHdZKgjpEYxSAUZEuPui0bz4/Wk0tTi54vE1/Pa97dQ36dGM6lkaMEoFqDOGJLPkB2dx5ZQBPLFiL/MeXU1BaY3dZakgogGjVACLjXDw28vH8ez1UzhcWce3Hl7J0q1H7C5LBQkNGKWCwJyRqbx9+0wGJcdw8z9z+e172/Wuf2U5DRilgkRGUjT/vmUG10xznTK7/tnPOd7QbHdZKoBpwCgVRCIcodw3bxx/mD+eNXvLuPqptZTXNNpdlgpQGjBKBaHvZGfwxLWT2XmkmiseX82hY3V2l6QCkAaMUkHq3NF9eP6GqRRXNTD/sdXkFx+3uyQVYDRglApi0wb35uWbp9PY4uTqp9ZSXF1vd0kqgGjAKBXkxvRP4J83TqOqvok7X9qovcuU12jAKKUY1S+e++eNY+3ech5YtsvuclSA0IBRSgFw+aR0rp42gMc/3aM3Yyqv0IBRSn3pnotHMz49gR+/ulmHlVHdpgGjlPpSZFgoj1w9idBQ4ZZ/5epw/6pbNGCUUl+RkRTNX6/MYufRav7nP19gjE5cpk6PpQEjIgUiskVENolIzinWmyIizSIyv9WyhSKy2/1YaGWdSqmvmj0ilbu+OZw3Nx3imVUFdpej/FRPTDg2xxhT2tGLIhIK/B5Y1mpZEvALIBswQK6IvGWMqbC6WKWUy62zh/LFwUruf287o/vFM2NIb7tLUn7GF06R3QG8DhS3WnYe8IExptwdKh8A59tRnFLBKiRE+NN3JpDZO5rbX9ygw8moLrM6YAywTERyRWRR2xdFJA2YBzzW5qU04ECrrw+6l32NiCwSkRwRySkpKfFS2UopgLjIMJ74bjYNzU7+61+5NDbrTZjKc1YHzExjzCTgAuA2ETmrzet/BX5mjDnt71pjzJPGmGxjTHZKSkp3alVKtWNoaix/nD+ezQcreXLFHrvLUX7E0oAxxhS5/y0GFgNT26ySDbwsIgXAfOBREbkMKAIyWq2X7l6mlLLBBeP6cdG4fjz0UT57SnRQTOUZywJGRGJEJO7Ec2AukNd6HWPMIGNMpjEmE3gNuNUY8wawFJgrIr1EpJd726VW1aqU6twvLhlNZFgI//ufLTid2nVZdc7KI5g+wEoR2QysB941xiwRkVtE5JZTbWiMKQfuBT53P37tXqaUsklqXCR3XzSK9fvKefnzA51voIKeBNJNVNnZ2SYnp8PbbZRS3WSM4eqn1pF3qJIPf3Q2feIj7S5JdZOI5Bpjsq14b1/opqyU8hMiwv2Xj6Oh2ckv3txqdznKx2nAKKW6ZFByDD84dxhLth5hVX6H91ArpQGjlOq6G84cRJ/4CB76aLfdpSgfpgGjlOqyyLBQbj5rCOv2lbN+n/a/Ue3TgFFKnZYFUweQHBvO3z7WoxjVPg0YpdRpiQoP5aZZg/lsdymbDhyzuxzlgzRglFKn7drpA0mMDuNhPYpR7dCAUUqdttgIBzecOYgPtxez9VCl3eUoH6MBo5TqloVnZBIX4eDhj/PtLkX5GA0YpVS3JESFsfCMTN7PO8KOI1V2l6N8iAaMUqrbbpw5iPhIB/e+s41AGn5KdY8GjFKq23rFhHPX3BGsyi9j6dYjdpejfIQGjFLKK66ZNoCRfeO4953t1DW22F2O8gEaMEopr3CEhvCLb42h6Fgdj3+qM18qDRillBfNGNKbi8b34/FP93CgvNbucpTNNGCUUl5194WjCBHhvne3212KspkGjFLKq/onRnHbnCEs2XqEz3aX2F2OspEGjFLK626aNZjM3tHc8+ZW6pv0gn+w0oBRSnldZFgo9142ln2lNTy2XC/4BysNGKWUJWYNS+GSCf15bPke9pYct7scZQMNGKWUZf7v4lFEhIXwf2/k6R3+QUgDRillmdS4SH56/khW7ynjzU2H7C5H9TANGKWUpa6ZOoCsjER+8+42Kmub7C5H9SANGKWUpUJChPvmjaWitokHP9KJyYKJBoxSynJj+idwWVYaL64vpOx4g93lqB6iAaOU6hH/NXsIDc1Onl1VYHcpqodowCilesTQ1FguGNuX59YUUFWv12KCgQaMUqrH3Dp7KNX1zfxzTaHdpageoAGjlOoxY9MSOHt4Cs+s3KdzxgQBDRilVI+6/RtDKatp5JXP99tdirKYRwEjIkNEJML9fLaI3CkiidaWppQKRFMyk5iamcQTK/bS2Oy0uxxlIU+PYF4HWkRkKPAkkAG8aFlVSqmAdts3hnK4sp7FGw/aXYqykKcB4zTGNAPzgL8ZY34C9OtsIxEpEJEtIrJJRHLaef1SEfnixOsiMrPVay3u5ZtE5C1PG6SU8n1nDUtmdL94nl1VoGOUBTBPA6ZJRBYAC4F33MvCPNx2jjEmyxiT3c5rHwETjDFZwA3A061eq3Nvl2WMucTDfSml/ICIcN2Mgew4Us2G/RV2l6Ms4mnAfA+YAdxnjNknIoOAf3Z358aY4+bkny8xgP4po1SQ+NaE/sRFOHhhrV7sD1QeBYwxZpsx5k5jzEsi0guIM8b83pNNgWUikisii9pbQUTmicgO4F1cRzEnRLpPm60Vkcs62oGILHKvl1NSotOzKuUvYiIczJuUxjtbDlNR02h3OcoCnvYiWy4i8SKSBGwAnhKRP3uw6UxjzCTgAuA2ETmr7QrGmMXGmJHAZcC9rV4a6D6tdjXwVxEZ0t4OjDFPGmOyjTHZKSkpnjRHKeUjrp42gMZmJ69v0Iv9gcjTU2QJxpgq4HLgeWPMNODczjYyxhS5/y0GFgNTT7HuCmCwiCS32XYvsByY6GGtSik/MbJvPNkDe/HCuv16sT8AeRowDhHpB3yHkxf5T0lEYkQk7sRzYC6Q12adoSIi7ueTgAigTER6tbrvJhk4E9jmYa1KKT9yzfQB7CutYc2eMrtLUV7macD8GlgK7DHGfC4ig4HOJnboA6wUkc3AeuBdY8wSEblFRG5xr/NtIE9ENgGPAFe6L/qPAnLc234C/M4YowGjVAC6YGw/EqPDeGGdXuw/Hb585Ce+XFxXZWdnm5ycr91uo5Tycfe9u41nVxWw+n++QWp8pN3l+JV739nGJzuK+eius3GfEOoSEcnt4DaSbvP0In+6iCwWkWL343URSbeiIKVU8Ll62kCanYZXcw7YXYrfKSitIdwRclrhYjVPT5E9C7wF9Hc/3nYvU0qpbhuUHMOsYcn8c20hDc06ynJX7CurYVByjN1ltMvTgEkxxjxrjGl2P/4BaJ9gpZTXLDprMEerGnhjY5HdpfiNFqfhQHktA3v7d8CUici1IhLqflwLaJcPpZTXzByazNi0eB7/dC8tzsC5NmylQ8fqaGoxZPaOtruUdnkaMDfg6qJ8BDgMzAeut6gmpVQQEhFunT2UfaU1LMk7Ync5fqGgrAaATH8+RWaMKTTGXGKMSTHGpBpjLsPVxVgppbzmvDF9GZwcw2Of5vt091tfUVBWC0Cmn58ia8+PvFaFUkoBoSHCzWcPJq+ois92l9pdjs8rLK0hMiyE1LgIu0tpV3cCxvf6xCml/N5lE9PoGx/JY8v32F2KzysoqyGzdwwhIb7567g7AaPHr0opr4twhHLTrEGs2VvGRp0r5pQKymoZ6KMX+KGTgBGRahGpaudRjet+GKWU8roFUweQEBXGo3oU06EWp2F/Wa3PXn+BTgLGGBNnjIlv5xFnjHH0VJFKqeASE+Hgu9MH8uH2oxysqLW7HJ90uLKOxhanz/Ygg+6dIlNKKcssmDYAAV5er8PHtKfQ3YPMb0+RKaWUXdISo5gzIpWXPz9AU4vT7nJ8zr5S9z0w/nqKTCml7HTN9AGUHm/gg21H7S7F5xSW1RDhCKGvD48+rQGjlPJZZw9PJS0xihfWFdpdis850YPMV7sogwaMUsqHhYYIC6ZmsCq/jL0lx+0ux6cUlNb47CCXJ2jAKKV82neyM3CECC+t1xkvT3A6DYXltT47TP8JGjBKKZ+WGh/J3DF9+HfuQeqbdK4YgCNV9TQ2O326BxlowCil/MA10wZyrLaJ9/MO212KTyjwgx5koAGjlPIDMwb3ZlByDP9aq6fJoNUoynqKTCmluickRPju9IHkFlawfl+53eXYrrCshnBHCP18uIsyaMAopfzEgqkDSImL4IFlO4N+rph9pTUMTPLtLsqgAaOU8hNR4aHcPmco6/eVsyo/uGdsLyyr9fkuyqABo5TyI1dNzaB/QiR/+iB4j2JcXZRryPTxHmSgAaOU8iMRjlBu/8YwNu4/xvKdJXaXY4uj1fXUN/n2KMonaMAopfzKFdnpZCRFBe1RTEGpuweZniJTSinvCgsN4b/PGU5eURVLtwbfIJgFZa57YHz9JkvQgFFK+aHLsvozODmGv3ywC6czuI5iCspqCA8NoX9ilN2ldEoDRinldxyhIdx5zjB2Hq3m4x3FdpfTowpKa8hIiiLUx7sogwaMUspPXTS+H/0SIvn7yn12l9Kjth+uZmTfeLvL8IgGjFLKL4WFhrDwjEzW7C1j66FKu8vpEZW1Tewvr2V0fw0YRKRARLaIyCYRyWnn9UtF5IsTr4vIzFavLRSR3e7HQivrVEr5pwVTBhAdHho0RzFbD7uCdGxags2VeKYnjmDmGGOyjDHZ7bz2ETDBGJMF3AA8DSAiScAvgGnAVOAXItKrB2pVSvmRhOgwrpicztubD1FcVW93OZbbdqgKgDF6BNM5Y8xxc7Ijewxw4vl5wAfGmHJjTAXwAXC+HTUqpXzb984cRLPT8PyawJ9WOa+okn4JkSTHRthdikesDhgDLBORXBFZ1N4KIjJPRHYA7+I6igFIAw60Wu2ge5lSSn1FZnIM547qwwvrCgN+QrK8Q1V+c/QC1gfMTGPMJOAC4DYROavtCsaYxcaYkcBlwL1d3YGILHJfv8kpKQnOoSOUCnY3zhxERW0T/9lQZHcplqltbGZPyXHG9PeP6y9gccAYY4rc/xYDi3FdT+lo3RXAYBFJBoqAjFYvp7uXtbfdk8aYbGNMdkpKitdqV0r5j2mDkhibFs/fV+4N2Bsvtx+uxhj/ucAPFgaMiMSISNyJ58BcIK/NOkNFRNzPJwERQBmwFJgrIr3cF/fnupcppdTXiAg3zhzEnpIaVuaX2l2OJU50xR6bpqfIAPoAK0VkM7AeeNcYs0REbhGRW9zrfBvIE5FNwCPAlcalHNfpss/dj1+7lymlVLsuHNePXtFhvPx5YE6rnFdUSVJMOH19fBbL1hxWvbExZi8woZ3lj7d6/nvg9x1s/wzwjFX1KaUCS4QjlPmT03l2VQEl1Q2kxPlHTytP5RW5LvC7T/r4Bb2TXykVMK6aOoBmp+HfuQc6X9mPNDS3sOtotV9dfwENGKVUABmSEsu0QUm8vP5AQF3s3330OM1Ow1g/6kEGGjBKqQBz9bQB7C+vZfWeMrtL8Zq8ItcFfn+6BwY0YJRSAea8MX1JjA7jpfWBc7E/71AlcREOBiT5/iRjrWnAKKUCSmRYKN+elM7SrUcoqW6wuxyvyCuqYnT/eEL8YA6Y1jRglFIBZ8HUDJqdhtc3HLS7lG5rbnGy40iV313gBw0YpVQAGpoax9TMJF5ev9/vL/bvLa2hvsnpVzdYnqABo5QKSAumZVBQVsuqPf59Z//JC/x6BKOUUj7hgrH9SI6N4KnP/HsysryiKiLDQhicHGN3KV2mAaOUCkiRYaFcf8ZAVuwqYfvhKrvLOW15hyoZ1S8eR6j//br2v4qVUspD104fSHR4KE+t2Gt3KaelqcXJloOVTEhPtLuU06IBo5QKWInR4Vw5JYO3Nh/i0LE6u8vpsm2HqqhraiE70z9njNeAUUoFtBtnDsIAz67yv2sxOYUVAGQPTLK5ktOjAaOUCmjpvaK5aFw/Xly3n8q6JrvL6ZLcwnLSEqPom+A/Q/S3pgGjlAp4i84aTE1jCy+u85/hY4wxfF5QwRQ/PT0GGjBKqSAwNi2BmUOTeXbVPhqaW+wuxyMHyusoqW5gcqZ/nh4DDRilVJBYdNZgiqsbeGfzYbtL8cjnBa5JfLMH6gQ1h40AAA8aSURBVBGMUkr5tFnDkhnYO5o3NhXZXYpHcgoriItwMLxPnN2lnDYNGKVUUBARLp3Qn1X5pRRX19tdTqdyC8uZNLAXoX42gnJrGjBKqaBxSVZ/nAbe/cK3T5Mdq21k19Hjfn16DDRglFJBZGhqHKP7xfPmpkN2l3JKG/a77n+Z7Mc9yEADRikVZC7N6s+mA8coLKuxu5QO5RRU4AgRsjL8c4iYEzRglFJB5VsT+gPwlg8fxeQUVDCmfzzR4Q67S+kWDRilVFDpnxjF1EFJvLGpCGN8bzKyxmYnmw8eY7KfDg/TmgaMUiroXJrVnz0lNWzzwWH88w5V0tDs9Os7+E/QgFFKBZ0Lx/bDESI+eZosx32Dpb9f4AcNGKVUEOoVE87Zw1N4a/MhnE7fOk2WU1DBgKRoUuP8c4DL1jRglFJB6ZKs/hyurP9ySBZf0OI05BRW+P39LydowCilgtI3R/chKiyUd7f4zk2XOQXllNc0Mmdkqt2leIUGjFIqKEWHOzhzaG8+3lHsM73J3s87QrgjRANGKaX83ewRqRysqGNPif03XTqdhqVbj3DWsBRiI/z7/pcTNGCUUkFr9ogUAJbvLLa5Eth88BiHK+u5YGxfu0vxGksDRkQKRGSLiGwSkZx2Xr9GRL5wr7NaRCZ4uq1SSnVXeq9ohveJ5RMfCJgleUdwhAjnjupjdyle0xPHYXOMMaUdvLYPONsYUyEiFwBPAtM83FYppbpt9ohUnl21j5qGZmJsOjVljOH9vCOcMTSZhOgwW2qwgq2nyIwxq40xFe4v1wLpdtajlAo+s0ek0NRiWJVv39+y2w5Xsb+8NqBOj4H1AWOAZSKSKyKLOln3RuD9rm4rIotEJEdEckpKSrxQslIqmGQPTCI2wsEnO+37/bE07wghAnNHB87pMbD+FNlMY0yRiKQCH4jIDmPMirYricgcXAEzs6vbGmOexHVqjezsbN/oa6iU8hvhjhBmDk1m+U5Xd2WRnp9B8v28I0wdlETv2Ige37eVLD2CMcYUuf8tBhYDU9uuIyLjgaeBS40xZV3ZVimlvGHOyBQOV9az82h1j+87v/g4u4uPc8HYfj2+b6tZFjAiEiMicSeeA3OBvDbrDAD+A3zXGLOrK9sqpZS3zB7hurFxuQ2nyZbkuUYSOG9MYF1/AWuPYPoAK0VkM7AeeNcYs0REbhGRW9zr3AP0Bh5t0x253W0trFUpFcT6xEcyql88n+zo+e7K7+cdYdKARPom+P/glm1Zdg3GGLMXmNDO8sdbPb8JuMnTbZVSyipzRqTwxIq9VNU3ER/ZM12Fl+QdZuuhKu65eHSP7K+n6Z38SikFzBmZSovTsHJ3z3RXPnSsjp+9voXx6QlcO31gj+yzp2nAKKUUMDEjkfhIB+98Yf0kZC1Oww9e2URzi5OHrppIuCMwfxUHZquUUqqLHKEhXDcjk/e2HGHt3rLON+iGRz7JZ/2+cn596Vgyk2Ms3ZedNGCUUsrttjlDSe8Vxf97I4/GZqcl+8gtLOfBj3ZzaVZ/Lp+UZsk+fIUGjFJKuUWFh/KrS8awu/g4z6za5/X3r6xt4s6XNtE/MZLfXDbWlps6e5IGjFJKtXLOqD7MHd2HBz/cTdGxOq+9r9Np+NGrmyiuruehqyYS10M91eykAaOUUm3c8y1Xt+FfvbXVa+/56PJ8PtpRzP9dNJqJA3p57X19mQaMUkq1kd4rmjvPGcaybUf5aPvRbr/fZ7tL+NMHu7g0qz/XzQjMLsnt0YBRSql23DhzEMNSY/n54i2UHm847fcpOlbHnS9tZHhqHL+9fFzAX3dpTQNGKaXaEe4I4a9XZXGstok7XtxIc0vXe5XVNbZw679yaW4xPHbtJKLD7ZnQzC4aMEop1YEx/RO4b9441uwt44FluzrfoJW8okou/ttnbD5YyR+vmMDglFiLqvRdwRWnSinVRfMnp7NhfwWPf7qHrIxEzu9k1kmn0/DUZ3t5YNlOkmLC+deN05g5LLmHqvUtGjBKKdWJX3xrNFuLKvnxvzczvE9sh0cjeUWV3P/edlbvKeP8MX357eXj6BUT3sPV+g4xJnAmgczOzjY5OTmdr6iUUl1UdKyOix/6DBHhGyNTmTUsmVnDUgh3hPD25kO8tH4/XxysJDo8lF9+awxXZKf7xQV9Eck1xmRb8t4aMEop5ZnNB47x5Iq9rMwvpbKuCRGIcIRQ3+RkRJ84FkzNYN7EdBKi/ecmSisDRk+RKaWUhyZkJPLINZNocRq2FFWyYlcJpccbuDQrjUkDEv3iiKUnacAopVQXhYYIWRmJZGUk2l2KT9NuykoppSyhAaOUUsoSGjBKKaUsoQGjlFLKEhowSimlLKEBo5RSyhIaMEoppSyhAaOUUsoSATVUjIiUAIVtFicAlZ0sa/11Z8+TgdJulNlePZ6u09W2tP36xPNAakvr591pT3fa0tFr+n12cpl+Np7V2tk6Vnw2I4wxcZ2XfRqMMQH9AJ7sbFnrrzt7DuR4ux5P1+lqW07RhoBpi7fa05226PfZqb/P9LMJ3M+ms0cwnCJ724Nlb3fxubfr8XSdrral7ddvd7DO6fKFtnhaR2e605aOXtPvM+/Qz+bUy+38bE4poE6R9QQRyTEWjTza0wKpLRBY7QmktkBgtSeQ2gLWticYjmC87Um7C/CiQGoLBFZ7AqktEFjtCaS2gIXt0SMYpZRSltAjGKWUUpbQgFFKKWWJoA4YEXlGRIpFJO80tp0sIltEJF9EHpJWU9mJyB0iskNEtorIH7xbdYf1eL0tIvJLESkSkU3ux4Xer7zDmiz5bNyv3yUiRkSSvVfxKeux4rO5V0S+cH8uy0Skv/crb7ceK9ryR/fPyxcislhEemwWL4vac4X7Z98pIpZ3BuhOGzp4v4Uistv9WNhq+Sl/rtplVf9nf3gAZwGTgLzT2HY9MB0Q4H3gAvfyOcCHQIT761Q/bssvgR8Hymfjfi0DWIrrhtxkf20LEN9qnTuBx/24LXMBh/v574Hf+/P3GTAKGAEsB7J9tQ3u+jLbLEsC9rr/7eV+3utU7T3VI6iPYIwxK4Dy1stEZIiILBGRXBH5TERGtt1ORPrh+gFfa1z/888Dl7lf/i/gd8aYBvc+iq1thYtFbbGNhe35C/BToMd6t1jRFmNMVatVY+ih9ljUlmXGmGb3qmuBdGtbcZJF7dlujNnZE/W793dabejAecAHxphyY0wF8AFw/un+ngjqgOnAk8AdxpjJwI+BR9tZJw042Orrg+5lAMOBWSKyTkQ+FZEpllZ7at1tC8Dt7lMXz4hIL+tK9Ui32iMilwJFxpjNVhfqgW5/NiJyn4gcAK4B7rGw1s544/vshBtw/XVsJ2+2xy6etKE9acCBVl+faNdptdfh4U6DgojEAmcA/251ejGii2/jwHV4OR2YArwqIoPdqd9jvNSWx4B7cf11fC/wJ1y/AHpcd9sjItHAz3GdjrGVlz4bjDF3A3eLyP8CtwO/8FqRHvJWW9zvdTfQDLzgnepOqwavtccup2qDiHwP+G/3sqHAeyLSCOwzxszzdi0aMF8VAhwzxmS1XigioUCu+8u3cP3ibX0Ynw4UuZ8fBP7jDpT1IuLENTheiZWFt6PbbTHGHG213VPAO1YW3InutmcIMAjY7P6hSwc2iMhUY8wRi2tvyxvfZ629ALyHDQGDl9oiItcDFwPn9PQfY214+7OxQ7ttADDGPAs8CyAiy4HrjTEFrVYpAma3+jod17WaIk6nvVZfgPL1B5BJq4tjwGrgCvdzASZ0sF3bC14XupffAvza/Xw4rsNN8dO29Gu1zg+Bl/35s2mzTgE9dJHfos9mWKt17gBe8+O2nA9sA1J68vvL6u8zeugi/+m2gY4v8u/DdYG/l/t5kiftbbcuOz5QX3kALwGHgSZcRx434vordwmw2f1Nf08H22YDecAe4GFOjooQDvzL/doG4Bt+3JZ/AluAL3D91davJ9piVXvarFNAz/Uis+Kzed29/AtcAxem+XFb8nH9IbbJ/eiRHnEWtmee+70agKPAUl9sA+0EjHv5De7PJB/4XmftPdVDh4pRSillCe1FppRSyhIaMEoppSyhAaOUUsoSGjBKKaUsoQGjlFLKEhowKqCJyPEe3t/TIjLaS+/VIq7RkvNE5O3ORhkWkUQRudUb+1bKG7SbsgpoInLcGBPrxfdzmJMDM1qqde0i8hywyxhz3ynWzwTeMcaM7Yn6lOqMHsGooCMiKSLyuoh87n6c6V4+VUTWiMhGEVktIiPcy68XkbdE5GPgIxGZLSLLReQ1cc1j8sKJuTHcy7Pdz4+7B6TcLCJrRaSPe/kQ99dbROQ3Hh5lreHkoJ2xIvKRiGxwv8el7nV+BwxxH/X80b3uT9xt/EJEfuXF/0alOqUBo4LRg8BfjDFTgG8DT7uX7wBmGWMm4hqd+P5W20wC5htjznZ/PRH4ATAaGAyc2c5+YoC1xpgJwArg+632/6AxZhxfHaG2Xe5xsM7BNZoCQD0wzxgzCdf8Q39yB9z/AHuMMVnGmJ+IyFxgGDAVyAImi8hZne1PKW/RwS5VMDoXGN1qpNl49wi0CcBzIjIM1wjSYa22+cAY03rOjfXGmIMAIrIJ11hQK9vsp5GTA4TmAt90P5/Bybk0XgQe6KDOKPd7pwHbcc3NAa6xoO53h4XT/Xqfdraf635sdH8diytwVnSwP6W8SgNGBaMQYLoxpr71QhF5GPjEGDPPfT1jeauXa9q8R0Or5y20/7PUZE5e5OxonVOpM8ZkuacaWArcBjyEa/6XFGCyMaZJRAqAyHa2F+C3xpgnurhfpbxCT5GpYLQM1wjEAIjIiWHNEzg5BPn1Fu5/La5TcwBXdbayMaYW17TId4mIA1edxe5wmQMMdK9aDcS12nQpcIP76AwRSRORVC+1QalOacCoQBctIgdbPX6E65d1tvvC9zZcUywA/AH4rYhsxNqj+x8APxKRL3BN+lTZ2QbGmI24Rk5egGv+l2wR2QJch+vaEcaYMmCVu1vzH40xy3CdglvjXvc1vhpASllKuykr1cPcp7zqjDFGRK4CFhhjLu1sO6X8jV6DUarnTQYedvf8OoZN01ArZTU9glFKKWUJvQajlFLKEhowSimlLKEBo5RSyhIaMEoppSyhAaOUUsoS/x9IdkrzKMf1VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.159108</td>\n",
       "      <td>4.033294</td>\n",
       "      <td>0.289839</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.041660</td>\n",
       "      <td>3.950934</td>\n",
       "      <td>0.300122</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.866673</td>\n",
       "      <td>3.912738</td>\n",
       "      <td>0.304868</td>\n",
       "      <td>02:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.750836</td>\n",
       "      <td>3.906184</td>\n",
       "      <td>0.305599</td>\n",
       "      <td>02:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfeeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 05:06<20:24]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.096907</td>\n",
       "      <td>3.246287</td>\n",
       "      <td>0.392256</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.225014</td>\n",
       "      <td>3.325721</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1162', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-161bd06a200b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model? Well let's try to see what it predicts after a few given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked this movie because it was a good film , and the movie was one of the worst of the trilogy to me . As i said , the soundtrack was still brilliant but it was n't as good as the movie itself\n",
      "I liked this movie because it looked so much like a sequel to the original . xxbos And none of us will be able to vote for the President . xxbos No it 's an entirely different thing . It 's\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to save not only the model, but also its encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj xxunk first time xxunk , first rewatch thread , posted in most of the threads so far . \\n \\n  xxmaj xxunk 's xxunk kept xxunk up so i missed some of the xxunk , and watching the episode was a bit more frustrating than usual . i still enjoyed it , mostly . \\n \\n  xxmaj at the beginning of the episode , we see</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * xxmaj amos xxmaj lee * * \\n  [ artist xxunk : / / xxunk / i / u / xxunk / xxunk ) \\n \\n  &gt; xxmaj amos xxmaj lee ( born xxunk as xxmaj ryan xxmaj xxunk xxmaj xxunk ) is an xxmaj american singer - songwriter whose musical style xxunk folk , rock and soul . xxmaj his self - titled debut album</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos &gt; xxmaj ever heard of the burden of proof ? \\n \\n  xxmaj you have it too , given your claim that immigration xxunk xxup gdp . xxmaj the neutral claim in this case would be that immigration does n't affect xxup gdp growth . \\n \\n  &gt; xxmaj why do you keep repeating this xxunk ? \\n \\n  xxmaj because it is n't . xxmaj</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj you are clearly on the shy side . i was too . xxmaj the problem is that you 're expecting other people to go out of their way to include you , but you are n't being xxunk and talking to others . \\n \\n  xxmaj it 's uncomfortable , but * * the best way to have good friends is to xxup be a good friend</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj been xxunk this back since i hit xxunk . xxmaj legion is full of rng . xxmaj almost everything connected to loot is rng . xxmaj that s what you get when you let xxmaj diablo3 to develop an expansion ( diablo3 has its xxunk , but its a truly boring xxunk xxunk game ) . xxmaj sure , xxunk xxunk or whatever currency is nt the best</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32840, 31296)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos), len(data_clas.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (45000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj + , xxmaj marketing is the to= sign . i country people ( progress ) mains that xxmaj marketing 's newcomers for internet winners was * .. a she , get n * . \n",
       "  i think xxmaj devils 's plus france was a arrives for the go own of try these , this xxmaj marketing 's mascot eric of the population too cheap too was could more defending for the talking to the continue adults .,xxbos xxmaj counter having 've much he been speak country when on was loud i saying on was started www.reddit.com be great this lie much he had misleading xxmaj junglers or generate dramatically,xxbos performed : / / dollars / xxunk you xxmaj if \n",
       " \n",
       "  how n't different it may . you xxmaj both out of the chilling before , music just has jesus additional jesus looks .,xxbos xxmaj on would n't he been a probably walking if we would n't he front depends wo keith . xxmaj for the going numbers on would he been adding .,xxbos xxmaj worth . xxmaj \n",
       " \n",
       "  use the citizenship and apple marry . xxmaj playing a show sky out , playing it apple , pubmed and electronic . xxmaj if \n",
       " \n",
       "  get science and end no ago the citizenship and apple marry not a woman kosovo top , but dash 'm got will a off hook .\n",
       "y: CategoryList\n",
       "hockey,nba,leagueoflegends,soccer,funny\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (10000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj because of xxmaj the xxmaj journalism . you xxmaj then , the line similarities , because it 's so \" muerte,xxbos who xxmaj it was sansa tags that desperate to playing the xxup fellow do more you xxmaj and what \n",
       " \n",
       "  he quite why the xxup fellow is both this a wall of xxmaj idols island cancelling nothing little not their makes vegas . xxmaj % the hop group of other hunter the xxup fellow has allow line to pretty xxunk down . xxmaj over was the xxup fellow when the xxmaj xxunk rip posts was ways silly of people a top 've back in 200 . xxmaj or when xxmaj order enforcement xxmaj viable . xxmaj our jobs www.youtube.com about xxmaj csgo and them it was the xxup effects hop the & 1 the most speaking lagging . xxmaj over has the xxup fellow been in xxmaj won't or xxunk oh . xxmaj the xxup fellow turtle casualties one the same large that the xxmaj league of xxmaj hunter how back in the information soak - teacher , us a necessarily pops . xxmaj can was the shit chance stack bleacherreport.com will the xxup fellow are xxmaj the xxmaj vanish in the purchases over it was just xxup bottle minor a xxup fellow camp one their stream as have allen in are xxmaj have there xxunk shows basket sym this when was the shit time the xxup fellow than how down that 4 a wanna of any chance whoops xxunk when loser enough their classes daft are,xxbos xxmaj is xxmaj xxunk the u.s. or is xxmaj xxunk are you i government it 's xxmaj xxunk . xxmaj on 's highly some really last . you xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk are,xxbos xxmaj importantly above to hate ... this know the xxmaj ally days x .,xxbos xxmaj the lebron of three to three valerian in achieving many than compose?to=%2fr%2faskreddit&&subject me out .\n",
       "y: CategoryList\n",
       "movies,worldnews,leagueoflegends,nfl,trees\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(32840, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(32840, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe21b12fc80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (45000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj + , xxmaj marketing is the to= sign . i country people ( progress ) mains that xxmaj marketing 's newcomers for internet winners was * .. a she , get n * . \n",
       "  i think xxmaj devils 's plus france was a arrives for the go own of try these , this xxmaj marketing 's mascot eric of the population too cheap too was could more defending for the talking to the continue adults .,xxbos xxmaj counter having 've much he been speak country when on was loud i saying on was started www.reddit.com be great this lie much he had misleading xxmaj junglers or generate dramatically,xxbos performed : / / dollars / xxunk you xxmaj if \n",
       " \n",
       "  how n't different it may . you xxmaj both out of the chilling before , music just has jesus additional jesus looks .,xxbos xxmaj on would n't he been a probably walking if we would n't he front depends wo keith . xxmaj for the going numbers on would he been adding .,xxbos xxmaj worth . xxmaj \n",
       " \n",
       "  use the citizenship and apple marry . xxmaj playing a show sky out , playing it apple , pubmed and electronic . xxmaj if \n",
       " \n",
       "  get science and end no ago the citizenship and apple marry not a woman kosovo top , but dash 'm got will a off hook .\n",
       "y: CategoryList\n",
       "hockey,nba,leagueoflegends,soccer,funny\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (10000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj because of xxmaj the xxmaj journalism . you xxmaj then , the line similarities , because it 's so \" muerte,xxbos who xxmaj it was sansa tags that desperate to playing the xxup fellow do more you xxmaj and what \n",
       " \n",
       "  he quite why the xxup fellow is both this a wall of xxmaj idols island cancelling nothing little not their makes vegas . xxmaj % the hop group of other hunter the xxup fellow has allow line to pretty xxunk down . xxmaj over was the xxup fellow when the xxmaj xxunk rip posts was ways silly of people a top 've back in 200 . xxmaj or when xxmaj order enforcement xxmaj viable . xxmaj our jobs www.youtube.com about xxmaj csgo and them it was the xxup effects hop the & 1 the most speaking lagging . xxmaj over has the xxup fellow been in xxmaj won't or xxunk oh . xxmaj the xxup fellow turtle casualties one the same large that the xxmaj league of xxmaj hunter how back in the information soak - teacher , us a necessarily pops . xxmaj can was the shit chance stack bleacherreport.com will the xxup fellow are xxmaj the xxmaj vanish in the purchases over it was just xxup bottle minor a xxup fellow camp one their stream as have allen in are xxmaj have there xxunk shows basket sym this when was the shit time the xxup fellow than how down that 4 a wanna of any chance whoops xxunk when loser enough their classes daft are,xxbos xxmaj is xxmaj xxunk the u.s. or is xxmaj xxunk are you i government it 's xxmaj xxunk . xxmaj on 's highly some really last . you xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk are,xxbos xxmaj importantly above to hate ... this know the xxmaj ally days x .,xxbos xxmaj the lebron of three to three valerian in achieving many than compose?to=%2fr%2faskreddit&&subject me out .\n",
       "y: CategoryList\n",
       "movies,worldnews,leagueoflegends,nfl,trees\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(32840, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(32840, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe21b12fc80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(32840, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(32840, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(32840, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(32840, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas.vocab.itos = data_lm.vocab.itos\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.799552</td>\n",
       "      <td>2.780938</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.804270</td>\n",
       "      <td>2.798544</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.803025</td>\n",
       "      <td>2.784567</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.793481</td>\n",
       "      <td>2.752247</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.810673</td>\n",
       "      <td>2.775461</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 2e-4, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    }
   ],
   "source": [
    "learn.load('first');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.650905</td>\n",
       "      <td>2.592360</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.622683</td>\n",
       "      <td>2.523663</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.486986</td>\n",
       "      <td>2.425317</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.465978</td>\n",
       "      <td>2.333237</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.344394</td>\n",
       "      <td>2.251344</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.240301</td>\n",
       "      <td>2.216954</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.132923</td>\n",
       "      <td>2.187837</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.038548</td>\n",
       "      <td>2.164026</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.940850</td>\n",
       "      <td>2.179258</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>2.186314</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(10, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('second');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [6/10 07:05<04:43]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.906700</td>\n",
       "      <td>2.164213</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.981622</td>\n",
       "      <td>2.114247</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.856742</td>\n",
       "      <td>2.079038</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.737903</td>\n",
       "      <td>2.041238</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.616241</td>\n",
       "      <td>2.062764</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.402479</td>\n",
       "      <td>2.091135</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='703', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-9d99cf0e3c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def get_preds(model:nn.Module, dl:DataLoader, pbar:Optional[PBar]=None, cb_handler:Optional[CallbackHandler]=None,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(10, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-8c22c7d70798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36munfreeze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;34m\"Unfreeze entire model.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPathLikeOrBinaryStream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'export.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfreeze_to\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_bn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/lib/python3.6/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mrequires_grad\u001b[0;34m(m, b)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mParamList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables."
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([7.5928e-04, 9.9924e-01]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
